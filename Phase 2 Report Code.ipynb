{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3WQkSf0a9kV",
        "outputId": "659c4bd1-2f41-43f7-c646-3e89058239b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "\n",
        "print(\"True.csv hits:\", glob.glob('/content/drive/MyDrive/**/True.csv', recursive=True)[:10])\n",
        "print(\"Fake.csv hits:\", glob.glob('/content/drive/MyDrive/**/Fake.csv', recursive=True)[:10])\n",
        "\n",
        "TRUE_PATH = '/content/drive/MyDrive/True.csv'\n",
        "FAKE_PATH = '/content/drive/MyDrive/Fake.csv'\n",
        "\n",
        "print(\"TRUE exists? \", os.path.exists(TRUE_PATH), \"->\", TRUE_PATH)\n",
        "print(\"FAKE exists? \", os.path.exists(FAKE_PATH), \"->\", FAKE_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccxcb64plPL5",
        "outputId": "11a73269-f528-4442-e404-2e17c546aead"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True.csv hits: ['/content/drive/MyDrive/True.csv']\n",
            "Fake.csv hits: ['/content/drive/MyDrive/Fake.csv']\n",
            "TRUE exists?  True -> /content/drive/MyDrive/True.csv\n",
            "FAKE exists?  True -> /content/drive/MyDrive/Fake.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "TRUE_CSV = Path(TRUE_PATH)\n",
        "FAKE_CSV = Path(FAKE_PATH)\n",
        "\n",
        "assert TRUE_CSV.exists(), f\"Missing: {TRUE_CSV}\"\n",
        "assert FAKE_CSV.exists(), f\"Missing: {FAKE_CSV}\"\n",
        "\n",
        "print(\"Using:\", TRUE_CSV, FAKE_CSV)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC2EvTfWlych",
        "outputId": "03f4ce0c-95b8-4f0d-c0bc-31bf111c685e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: /content/drive/MyDrive/True.csv /content/drive/MyDrive/Fake.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports and basic settings**:"
      ],
      "metadata": {
        "id": "OUb-TN5brYbq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FsU1TeBTD7z-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load ISOT Fake/True dataset:**"
      ],
      "metadata": {
        "id": "1bvNX9BUruUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_isot(fake_path, true_path):\n",
        "    fake_df = pd.read_csv(fake_path)\n",
        "    true_df = pd.read_csv(true_path)\n",
        "\n",
        "    fake_df[\"label\"] = \"fake\"\n",
        "    true_df[\"label\"] = \"true\"\n",
        "\n",
        "    # Combine two dataframes\n",
        "    df = pd.concat([fake_df, true_df], ignore_index=True)\n",
        "\n",
        "    # One text column = title + body\n",
        "    df[\"text_full\"] = df[\"title\"].fillna(\"\") + \" \" + df[\"text\"].fillna(\"\")\n",
        "\n",
        "    # Drop exact duplicate articles\n",
        "    df = df.drop_duplicates(subset=[\"title\", \"text\"])\n",
        "\n",
        "    # Keep only the columns we care about now\n",
        "    df = df[[\"text_full\", \"label\", \"subject\", \"date\"]]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# use the Path objects we already created\n",
        "df = load_isot(FAKE_CSV, TRUE_CSV)\n",
        "\n",
        "print(df.head())\n",
        "print(\"\\nLabel counts:\")\n",
        "print(df[\"label\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5F_JXQujcpn",
        "outputId": "4540ca72-3b69-494b-f765-6a60aa493168"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           text_full label subject  \\\n",
            "0   Donald Trump Sends Out Embarrassing New Year’...  fake    News   \n",
            "1   Drunk Bragging Trump Staffer Started Russian ...  fake    News   \n",
            "2   Sheriff David Clarke Becomes An Internet Joke...  fake    News   \n",
            "3   Trump Is So Obsessed He Even Has Obama’s Name...  fake    News   \n",
            "4   Pope Francis Just Called Out Donald Trump Dur...  fake    News   \n",
            "\n",
            "                date  \n",
            "0  December 31, 2017  \n",
            "1  December 31, 2017  \n",
            "2  December 30, 2017  \n",
            "3  December 29, 2017  \n",
            "4  December 25, 2017  \n",
            "\n",
            "Label counts:\n",
            "label\n",
            "true    21197\n",
            "fake    17908\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train / validation / test split:**"
      ],
      "metadata": {
        "id": "NRmnBGXOr5zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[\"text_full\"].values\n",
        "y = df[\"label\"].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train 70% vs temp 30%\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Validation 15% vs Test 15%\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Valid size:\", len(X_valid))\n",
        "print(\"Test size:\", len(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOqJmq8JoQib",
        "outputId": "95dd7025-7b6c-4192-e519-5566a47c658a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 27373\n",
            "Valid size: 5866\n",
            "Test size: 5866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing and vocabulary:**"
      ],
      "metadata": {
        "id": "TczsjbjysCL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "TOKEN_PATTERN = re.compile(r\"[a-z]+\")   # regex pattern to extract alphabetic tokens only (a–z)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Lowercase, remove URLs, keep alphabetic tokens only.\n",
        "    \"\"\"\n",
        "    text = text.lower()   # convert entire text to lowercase for consistency\n",
        "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)   # remove URLs and replace them with spaces\n",
        "    tokens = TOKEN_PATTERN.findall(text)   # extract alphabetic tokens using the regex pattern\n",
        "    return tokens    # return list of cleaned tokens\n",
        "\n",
        "\n",
        "def build_vocabulary(texts, min_freq=5):\n",
        "    \"\"\"\n",
        "    Build a word -> index dictionary from training texts.\n",
        "    Only keep words that appear at least min_freq times.\n",
        "    \"\"\"\n",
        "    freq = {}   # dictionary to count token frequencies across all training texts\n",
        "\n",
        "    for t in texts:\n",
        "        tokens = preprocess_text(t)   # preprocess each document\n",
        "        for tok in tokens:\n",
        "            freq[tok] = freq.get(tok, 0) + 1   # increment count or initialize to 1\n",
        "\n",
        "    vocab = {}   # final vocabulary mapping token -> index\n",
        "    idx = 0      # index counter\n",
        "    for word, count in freq.items():\n",
        "        if count >= min_freq:     # keep only words that occur enough times\n",
        "            vocab[word] = idx     # assign index to the word\n",
        "            idx += 1              # increment index for next word\n",
        "\n",
        "    return vocab   # return constructed vocabulary dictionary\n",
        "\n",
        "\n",
        "def vectorize_tokens(tokens, vocab):\n",
        "    \"\"\"\n",
        "    Convert list of tokens into a count vector.\n",
        "    \"\"\"\n",
        "    vec = np.zeros(len(vocab), dtype=np.int32)   # initialize vector of zeros, length = vocab size\n",
        "    for tok in tokens:\n",
        "        if tok in vocab:         # check if token exists in vocabulary\n",
        "            j = vocab[tok]       # get index of the token\n",
        "            vec[j] += 1          # increment count in the corresponding position\n",
        "    return vec    # return the bag-of-words count vector\n",
        "\n",
        "\n",
        "# Build vocabulary from the training set\n",
        "vocab = build_vocabulary(X_train, min_freq=5)   # construct vocabulary using training data\n",
        "print(\"Vocabulary size:\", len(vocab))           # print number of unique tokens kept\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHgQMN81oi74",
        "outputId": "0ae1baba-a724-4860-8523-55ccd5c0c83d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 35464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From-scratch Multinomial Naive Bayes:**"
      ],
      "metadata": {
        "id": "U7FCWv-2sKyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultinomialNBScratch:\n",
        "    \"\"\"\n",
        "    Simple Multinomial Naive Bayes for text classification.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha                      # Laplace smoothing parameter\n",
        "        self.classes_ = None                    # stores the class labels (e.g., [\"fake\", \"true\"])\n",
        "        self.class_priors_ = None               # P(class) for each class\n",
        "        self.feature_log_prob_ = None           # log P(word | class) matrix\n",
        "        self.vocab_ = None                      # reference to the vocabulary used\n",
        "\n",
        "    def fit(self, texts, labels, vocab):\n",
        "        \"\"\"\n",
        "        Train the Naive Bayes model on the given texts and labels.\n",
        "        \"\"\"\n",
        "        self.vocab_ = vocab                     # save the vocabulary\n",
        "        n_docs = len(texts)                     # number of documents in the training set\n",
        "\n",
        "        # find unique classes and map labels to numeric indices\n",
        "        self.classes_, y_indices = np.unique(labels, return_inverse=True)\n",
        "        n_classes = len(self.classes_)          # number of classes (2 in our case)\n",
        "        n_features = len(vocab)                 # size of vocabulary\n",
        "\n",
        "        # initialize word count matrix [num_classes x vocab_size]\n",
        "        class_word_counts = np.zeros((n_classes, n_features), dtype=np.int64)\n",
        "        class_doc_counts = np.zeros(n_classes, dtype=np.int64)   # document count per class\n",
        "\n",
        "        # loop over every training document\n",
        "        for i, text in enumerate(texts):\n",
        "            c_idx = y_indices[i]                # index of the class for this document\n",
        "            class_doc_counts[c_idx] += 1        # count how many docs belong to each class\n",
        "\n",
        "            tokens = preprocess_text(text)      # preprocess text into tokens\n",
        "            vec = vectorize_tokens(tokens, vocab)   # convert tokens into a count vector\n",
        "            class_word_counts[c_idx] += vec     # add counts to this class's word totals\n",
        "\n",
        "        # compute prior probabilities P(class)\n",
        "        self.class_priors_ = class_doc_counts / n_docs\n",
        "\n",
        "        # apply Laplace smoothing to word counts\n",
        "        alpha = self.alpha\n",
        "        smoothed = class_word_counts + alpha\n",
        "\n",
        "        # sum of word counts for each class (needed for normalization)\n",
        "        class_totals = smoothed.sum(axis=1).reshape(-1, 1)\n",
        "\n",
        "        # compute conditional probabilities P(word | class) in log-space\n",
        "        self.feature_log_prob_ = np.log(smoothed / class_totals)\n",
        "\n",
        "    def _log_posterior(self, text):\n",
        "        \"\"\"\n",
        "        Compute log posterior probabilities for each class for a single document.\n",
        "        \"\"\"\n",
        "        tokens = preprocess_text(text)                 # preprocess text\n",
        "        vec = vectorize_tokens(tokens, self.vocab_)    # convert to count vector\n",
        "\n",
        "        # log likelihood: sum(count * log P(word|class)) over all words\n",
        "        log_likelihood = (self.feature_log_prob_ * vec).sum(axis=1)\n",
        "\n",
        "        # log prior: log(P(class))\n",
        "        log_prior = np.log(self.class_priors_)\n",
        "\n",
        "        # log posterior for each class\n",
        "        return log_prior + log_likelihood\n",
        "\n",
        "    def predict(self, texts):\n",
        "        \"\"\"\n",
        "        Predict class labels for a list of texts.\n",
        "        \"\"\"\n",
        "        preds = []\n",
        "        for t in texts:\n",
        "            log_post = self._log_posterior(t)          # compute log posteriors\n",
        "            c_idx = np.argmax(log_post)                # choose class with highest score\n",
        "            preds.append(self.classes_[c_idx])         # map index back to class label\n",
        "        return np.array(preds)\n"
      ],
      "metadata": {
        "id": "j-97VQaoo6gs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Small subset experiment:**"
      ],
      "metadata": {
        "id": "LLW6w5NJsSz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset_size = 1000\n",
        "test_subset_size = 300\n",
        "\n",
        "X_train_small = X_train[:train_subset_size]\n",
        "y_train_small = y_train[:train_subset_size]\n",
        "X_test_small = X_test[:test_subset_size]\n",
        "y_test_small = y_test[:test_subset_size]\n",
        "\n",
        "vocab_small = build_vocabulary(X_train_small, min_freq=3)\n",
        "print(\"Small vocab size:\", len(vocab_small))\n",
        "\n",
        "nb_small = MultinomialNBScratch(alpha=1.0)\n",
        "nb_small.fit(X_train_small, y_train_small, vocab_small)\n",
        "\n",
        "y_pred_small = nb_small.predict(X_test_small)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "acc_small = accuracy_score(y_test_small, y_pred_small)\n",
        "print(f\"Subset accuracy (scratch NB) = {acc_small:.4f}\")\n",
        "\n",
        "print(\"\\nClassification report (subset):\")\n",
        "print(classification_report(y_test_small, y_pred_small))\n",
        "\n",
        "cm_small = confusion_matrix(y_test_small, y_pred_small, labels=[\"fake\", \"true\"])\n",
        "print(\"Confusion matrix (rows=actual, cols=pred, order=[fake, true]):\\n\", cm_small)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCo1o8pppeYW",
        "outputId": "045b8dd4-f798-4ce9-847c-89815e13284f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small vocab size: 9752\n",
            "Subset accuracy (scratch NB) = 0.9533\n",
            "\n",
            "Classification report (subset):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.94      0.96      0.95       139\n",
            "        true       0.97      0.94      0.96       161\n",
            "\n",
            "    accuracy                           0.95       300\n",
            "   macro avg       0.95      0.95      0.95       300\n",
            "weighted avg       0.95      0.95      0.95       300\n",
            "\n",
            "Confusion matrix (rows=actual, cols=pred, order=[fake, true]):\n",
            " [[134   5]\n",
            " [  9 152]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Full train experiment:**"
      ],
      "metadata": {
        "id": "eYp2GRU2sYSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_full = build_vocabulary(X_train, min_freq=5)\n",
        "print(\"Full vocab size:\", len(vocab_full))\n",
        "\n",
        "nb_full = MultinomialNBScratch(alpha=1.0)\n",
        "nb_full.fit(X_train, y_train, vocab_full)\n",
        "\n",
        "y_pred_test = nb_full.predict(X_test)\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(f\"Test accuracy (scratch NB) = {acc_test:.4f}\")\n",
        "print(\"\\nClassification report (full test):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "cm_full = confusion_matrix(y_test, y_pred_test, labels=[\"fake\", \"true\"])\n",
        "print(\"Confusion matrix (rows=actual, cols=pred, order=[fake, true]):\\n\", cm_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAqhkrwEp20l",
        "outputId": "a0bff631-aeac-4434-9f4a-4f16ad0bfc58"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full vocab size: 35464\n",
            "Test accuracy (scratch NB) = 0.9535\n",
            "\n",
            "Classification report (full test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.95      0.95      0.95      2687\n",
            "        true       0.96      0.96      0.96      3179\n",
            "\n",
            "    accuracy                           0.95      5866\n",
            "   macro avg       0.95      0.95      0.95      5866\n",
            "weighted avg       0.95      0.95      0.95      5866\n",
            "\n",
            "Confusion matrix (rows=actual, cols=pred, order=[fake, true]):\n",
            " [[2552  135]\n",
            " [ 138 3041]]\n"
          ]
        }
      ]
    }
  ]
}